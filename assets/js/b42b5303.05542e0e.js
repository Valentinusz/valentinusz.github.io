"use strict";(self.webpackChunkvalentinusz_github_io=self.webpackChunkvalentinusz_github_io||[]).push([[474],{2930:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>i,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"bigdata/spark/rdd/index","title":"RDD","description":"Az RDD (Resilient Distributed Dataset - hibat\u0171r\u0151 elosztott adathalmaz) a Spark legalacsonyabb szint\u0171 adatmanipul\xe1ci\xf3s","source":"@site/notes/bigdata/02_spark/rdd/index.mdx","sourceDirName":"bigdata/02_spark/rdd","slug":"/bigdata/spark/rdd/","permalink":"/notes/bigdata/spark/rdd/","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"Boda B\xe1lint","lastUpdatedAt":1699279650000,"frontMatter":{},"sidebar":"notesSidebar","previous":{"title":"Spark - bevezet\xe9s","permalink":"/notes/bigdata/spark/"},"next":{"title":"L\xe9trehoz\xe1s","permalink":"/notes/bigdata/spark/rdd/creation"}}');var r=a(4848),s=a(8453);const i={},l="RDD",o={},d=[{value:"Inicializ\xe1l\xe1s",id:"inicializ\xe1l\xe1s",level:2}];function c(e){const t={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"rdd",children:"RDD"})}),"\n",(0,r.jsx)(t.p,{children:"Az RDD (Resilient Distributed Dataset - hibat\u0171r\u0151 elosztott adathalmaz) a Spark legalacsonyabb szint\u0171 adatmanipul\xe1ci\xf3s\neszk\xf6ze. Egy olyan adathalmazt reprezent\xe1l, melynek r\xe9szei a klaszter k\xfcl\xf6nb\xf6z\u0151 g\xe9pein helyezkednek el."}),"\n",(0,r.jsx)(t.p,{children:"Az adathalmaz tartalma, k\xfcl\xf6nb\xf6z\u0151 m\u0171veleteken kereszt\xfcl megv\xe1ltoztathat\xf3."}),"\n",(0,r.jsx)(t.h2,{id:"inicializ\xe1l\xe1s",children:"Inicializ\xe1l\xe1s"}),"\n",(0,r.jsx)(t.p,{children:"RDD l\xe9trehoz\xe1s el\u0151tt p\xe9ld\xe1nyos\xedtanunk kell a Spark konfigur\xe1ci\xf3 \xe9s kontextus objektumait."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-py",children:"from pyspark import SparkConf, SparkContext\n\nconf = SparkConf()\nsc = SparkContext(conf=conf)\n"})})]})}function p(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,t,a)=>{a.d(t,{R:()=>i,x:()=>l});var n=a(6540);const r={},s=n.createContext(r);function i(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);