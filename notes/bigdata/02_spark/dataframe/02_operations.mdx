# DataFrame műveletek

A műveletek többnyire megegyeznek az SQL-ből ismert műveletekkel.

Tekintsük az előző fejezetben is használt `dolgozo.csv` adatfájlt.

```py
from pyspark.sql import  *
from pyspark.sql.functions import *

spark = SparkSession.builder.getOrCreate()

df = spark.read.option('header', True).option('inferschema', True).csv('dolgozo.csv')
```

A műveletek használatához fontos megnézni, hogyan tudunk az oszlopokra hivatkozni. Erre három megoldás létezik:
- string literállal: `OSZLOP`
- adattagként: `df.OSZLOP` vagy `df['OSZLOP']` (ahol df a dataframe amibe az oszlop van)
- `col` függvénnyel: `col('OSZLOP')`

:::danger
A három hivatkozási mód általában ekvivalens, de néha előfordul, hogy nem kikövetkeztethető, hogy egy oszlopnevet
tartalmazó string literál tényleg oszlopra hivatkozik-e. Ekkor a másik módszerek egyikét kell használni.

Ilyen kifejezés például a `'JUTALEK' + 'FIZETES'`.
:::


## Vetítés

### `select(*cols)`

Oszlophivatkozásokat vár, és egy olyan dataframe-et ad vissza, mely a megadott oszlopokat tartalmazza.

```python
df.select('DNEV', df.FIZETES, df['FOGLALKOZAS'], col('OAZON')).show(4)
```

<div className='show-table'>
    | DNEV   | FIZETES | FOGLALKOZAS | OAZON |
    |--------|---------|-------------|-------|
    | KING   | 5000    | PRESIDENT   | 10    |
    | BLAKE  | 2850    | MANAGER     | 30    |
    | CLARK  | 2450    | MANAGER     | 10    |
    | JONES  | 2975    | MANAGER     | 20    |
</div>

Ezzel akár új oszlopokat is bevezethetünk:

```py
df.select(df.DNEV, (12 * df.FIZETES + 12 * df.JUTALEK).alias('KERESET')).show(4)
```

<div className='show-table'>
    | DNEV   | KERESET |
    |--------|---------|
    | KING   | 60000   |
    | BLAKE  | 34200   |
    | CLARK  | 29400   |
    | JONES  | 35700   |
</div>

:::note
A Python támogatja az operátor túlterhelést így a `(12 * df.FIZETES + 12 * df.JUTALEK)` kifejezés eredménye egy új
oszlop objektum, aminek az `alias()` metódussal adunk nevet.
:::

Hasonlóan az SQL-hez, ha a vetítésben szerepel a `*` karakter minden oszlop bele kerül az új dataframe-be.

```python
df.select('*').show(4)
```

<div className='show-table'>
    |DKOD|  DNEV|FOGLALKOZAS|FONOKE|  BELEPES|FIZETES|JUTALEK|OAZON|
    |----|------|-----------|------|---------|-------|-------|-----|
    |7839|  KING|  PRESIDENT|     0|81-NOV-17|   5000|      0|   10|
    |7698| BLAKE|    MANAGER|  7839|81-MAY-01|   2850|      0|   30|
    |7782| CLARK|    MANAGER|  7839|81-JUN-09|   2450|      0|   10|
    |7566| JONES|    MANAGER|  7839|81-APR-02|   2975|      0|   20|
</div>

### `selectExpr(*expr)`

Tudunk SQL kifejezés alapján is vetíteni. (Az SQL kifejezésekről a következő fejezetben lesz szó.)

```python
df.selectExpr('DNEV', '(FIZETES + JUTALEK) as KERESET').show(2)
```

<div className='show-table'>
    | DNEV  | KERESET |
    |-------|---------|
    | KING  | 5000    |
    | BLAKE | 2850    |
</div>

### `withColumn(colName, col)`
Hozzáveszi a dataframe-hez a `col` oszlopot, melyet `colName`-ként nevez el.

```python
df.withColumn('KERESET', df.FIZETES + df.JUTALEK).show(4)
```

<div className='show-table'>
    | DKOD | DNEV  | FOGLALKOZAS | FONOKE | BELEPES   | FIZETES | JUTALEK | OAZON | KERESET |
    |------|-------|-------------|--------|-----------|---------|---------|-------|---------|
    | 7839 | KING  | PRESIDENT   | 0      | 81-NOV-17 | 5000    | 0       | 10    | 5000    |
    | 7698 | BLAKE | MANAGER     | NULL   | 81-MAY-01 | 2850    | 0       | 30    | 2850    |
    | 7782 | CLARK | MANAGER     | 7839   | 81-JUN-09 | 2450    | 0       | 10    | 2450    |
    | 7566 | JONES | MANAGER     | 7839   | 81-APR-02 | 2975    | 0       | 20    | 2975    |
</div>

### `withColumnRenamed(existing, new)`
Átnevezi a megadott oszlopot. Ha nem létezik az oszlop létrehozza.

```python
df.withColumnRenamed('FIZETES', 'HAVI_FIZETES').show(4)
```

<div className='show-table'>
    | DKOD | DNEV   | FOGLALKOZAS | FONOKE | BELEPES   | HAVI_FIZETES | JUTALEK | OAZON |
    |------|--------|-------------|--------|-----------|--------------|---------|-------|
    | 7839 | KING   | PRESIDENT   | 0      | 81-NOV-17 | 5000         | 0       | 10    |
    | 7698 | BLAKE  | MANAGER     | NULL   | 81-MAY-01 | 2850         | 0       | 30    |
    | 7782 | CLARK  | MANAGER     | 7839   | 81-JUN-09 | 2450         | 0       | 10    |
    | 7566 | JONES  | MANAGER     | 7839   | 81-APR-02 | 2975         | 0       | 20    |
</div>

### `drop(*cols)`

A `drop()` metódussal lehetőségünk van oszlopokat elhagyni.

```python
df.drop(df.OAZON).show(4)
```

<div className='show-table'>
    | DKOD | DNEV  | FOGLALKOZAS | FONOKE | BELEPES   | FIZETES | JUTALEK |
    |------|-------|-------------|--------|-----------|---------|---------|
    | 7839 | KING  | PRESIDENT   | 0      | 81-NOV-17 | 5000    | 0       |
    | 7698 | BLAKE | MANAGER     | 7839   | 81-MAY-01 | 2850    | 0       |
    | 7782 | CLARK | MANAGER     | 7839   | 81-JUN-09 | 2450    | 0       |
    | 7566 | JONES | MANAGER     | 7839   | 81-APR-02 | 2975    | 0       |
</div>

## Lekérdezések ekvivalenciája

A következő művelettípus előtt beszélnünk kell kicsit, arról, hogy mikor számít kép művelet azonosnak. A Spark
(hasonlóan az adatbázis-kezelő rendszerekhez) egy végrehajtási tervet készít amit fizikai tervnek nevezünk.

Két lekérdezés ekvivalens ha a fizikai terveik megegyeznek, amit a `sameSemantics(self, dataframe)` metódussal tudunk
ellenőrizni.

```py
df.withColumn('KERESET', df.FIZETES + df.JUTALEK).sameSemantics(
    df.withColumn('KERESET', expr('FIZETES + JUTALEK'))
)
```

```
> True
```

Az egyes lekérdezések fizikai tervei az `explain()` metódussal kérhetőek le:
```python
df.withColumn('KERESET', df.FIZETES + df.JUTALEK).explain()
```

```
== Physical Plan ==
*(1) Project [DKOD#183, DNEV#184, FOGLALKOZAS#185, FONOKE#186, BELEPES#187, FIZETES#188, JUTALEK#189, OAZON#190, (FIZETES#188 + JUTALEK#189) AS KERESET#459]
+- FileScan csv [DKOD#183,DNEV#184,FOGLALKOZAS#185,FONOKE#186,BELEPES#187,FIZETES#188,JUTALEK#189,OAZON#190] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/bb200/Documents/elte-ik-bsc/5/bigdata/spark/07/dolgozo...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DKOD:int,DNEV:string,FOGLALKOZAS:string,FONOKE:int,BELEPES:string,FIZETES:int,JUTALEK:int,...
```

## Szűrés
Természetesen rendelkezésre áll a szűrés művelete is.

### `where(condition)`
```python
df.where(df.FIZETES > 3000).select(df.DNEV).show(5)
```

<div className='show-table'>
|DNEV|
|----|
|KING|
</div>


:::note
A `where()` alias a `filter()` metódusra.
:::

A különböző feltételeket az
- `&`: és
- `|`: vagy
- `~`: nem
logikai műveletekkel tudjuk összekapcsolni.

```python
df.filter((df.FIZETES > 2000) & ~(df.OAZON == 20)).show(4)
```

<div className='show-table'>
    | DKOD | DNEV  | FOGLALKOZAS | FONOKE | BELEPES   | FIZETES | JUTALEK | OAZON |
    |------|-------|-------------|--------|-----------|---------|---------|-------|
    | 7839 | KING  | PRESIDENT   | 0      | 81-NOV-17 | 5000    | 0       | 10    |
    | 7698 | BLAKE | MANAGER     | 7839   | 81-MAY-01 | 2850    | 0       | 30    |
    | 7782 | CLARK | MANAGER     | 7839   | 81-JUN-09 | 2450    | 0       | 10    |
</div>

:::danger
A `where()` láncolás más végrehajtási tervet eredményez, mintha a feltételeket logikailag kapcsoltuk volna össze.


```python
df.where(df.FIZETES > 2000).where(df.OAZON != 20).sameSemantics(
    df.where((df.FIZETES > 2000) & (df.OAZON != 20))
)
```

```
> False
```
:::

### `distinct()`
Megszünteti az ismétléseket.

```python
df.select(df.FOGLALKOZAS).distinct().count()
```

```
> 6
```

### `limit(n)`
Olyan dataframe-et állít elő, mely az eredeti dataframe első n sorát tartalmazza.

## Rendezés - `orderBy(*cols)`

A dataframe rendezhető. Ez, hogy az adott oszlop szerint növekvő vagy csökkenő sorrend legyen az `asc()` és `desc()`
hívásokkal specifikálható.

```python
df.orderBy(df.OAZON.asc(), df.FIZETES.desc()).show(5)
```

<div className='show-table'>
    | DKOD | DNEV   | FOGLALKOZAS | FONOKE | BELEPES   | FIZETES | JUTALEK | OAZON |
    |------|--------|-------------|--------|-----------|---------|---------|-------|
    | 7839 | KING   | PRESIDENT   | 0      | 81-NOV-17 | 5000    | 0       | 10    |
    | 7782 | CLARK  | MANAGER     | 7839   | 81-JUN-09 | 2450    | 0       | 10    |
    | 7934 | MILLER | CLERK       | 7782   | 82-JAN-23 | 1300    | 0       | 10    |
    | 7877 | LOLA   | CLERK       | 7902   | 81-JAN-12 | 800     | 0       | 10    |
    | 7788 | SCOTT  | ANALYST     | 7566   | 82-DEC-09 | 3000    | 0       | 20    |
</div>

## Csoportosítás - `groupBy()`
Csoportosításra is lehetőségünk van.

```python
df.groupBy(df.OAZON, df.FOGLALKOZAS).count().show()
```

<div className='show-table'>
    | OAZON | FOGLALKOZAS | count |
    |-------|-------------|-------|
    | 20    | ANALYST     | 2     |
    | 20    | NULL        | 1     |
    | 20    | MANAGER     | 1     |
    | 30    | MANAGER     | 1     |
    | 30    | SALESMAN    | 4     |
    | 30    | CLERK       | 1     |
    | 10    | PRESIDENT   | 1     |
    | 20    | CLERK       | 2     |
    | 10    | CLERK       | 2     |
    | 10    | MANAGER     | 1     |
    | ----  | ---------   | ----  |
</div>

A csoportokon mint SQL-ben végezhetünk összegezést. Ehhez az SQL-ben megismert összegző függvények is adottak
(`avg`, `max`, `min`, `sum`, `count`).

```python
df.groupBy(df.OAZON).agg(sum(df.FIZETES)).alias('OSSZ').show()
```

<div className='show-table'>
    | OAZON | sum(FIZETES) |
    |-------|--------------|
    | 20    | 12675        |
    | 10    | 9550         |
    | 30    | 9400         |
</div>

## Halmazműveletek
A halmazműveletek is elérhetők és az elvárt módon működnek:
- `substract()`: különbség
- `intersect()`: metszet
- `union()`: unió

## Összekapcsolás

Mint a táblák esetében lehetőségünk van a dataframe-ek összekapcsolására is. Ennek bemutatására először töltsünk be egy
másik dataframe-et.

```python
osztaly_df = spark.read.option('header', True).option('inferSchema', True).csv('osztaly.csv')
```

```python
osztaly_df.show()
```

<div className='show-table'>
    | OAZON | NEV        | TELEPHELY |
    |-------|------------|-----------|
    | 10    | ACCOUNTING | NEW YORK  |
    | 20    | RESEARCH   | DALLAS    |
    | 30    | SALES      | CHICAGO   |
    | 40    | OPERATIONS | BOSTON    |
</div>

### Keresztszorzat
Két dataframe keresztszorzata a `crossJoin()` metódussal képezhető.

```py
osztaly_df.crossJoin(osztaly_df)
```

### Théta összekapcsolás
Théta összekapcsolás a `join(other, [conditions], type)` metódus segítségével végezhető el.

Az összekapcsolási feltétel a második paraméterként feltételek tömbjeként adandó meg. Egy feltétel esetén a tömb
elhagyható. Harmadik paraméter az összekapcsolás típusa ('inner' vagy 'outer').

```python
df.join(osztaly_df, df.OAZON == osztaly_df.OAZON, 'inner').show(4)
```

<div className='show-table'>
    |DKOD|  DNEV|FOGLALKOZAS|FONOKE|  BELEPES|FIZETES|JUTALEK|OAZON|OAZON|       NEV|TELEPHELY|
    |---|----|---------|----|-------|-----|-----|---|---|--------|--------|
    |7839|  KING|  PRESIDENT|     0|81-NOV-17|   5000|      0|   10|   10|ACCOUNTING| NEW YORK|
    |7698| BLAKE|    MANAGER|  7839|81-MAY-01|   2850|      0|   30|   30|     SALES|  CHICAGO|
    |7782| CLARK|    MANAGER|  7839|81-JUN-09|   2450|      0|   10|   10|ACCOUNTING| NEW YORK|
    |7566| JONES|    MANAGER|  7839|81-APR-02|   2975|      0|   20|   20|  RESEARCH|   DALLAS|
</div>

### Természetes összekapcsolás

Ha természetes összekapcsolást szeretnénk végezni a feltételek helyett elég csak oszlopneveket megadni.

```python
df.join(osztaly_df, 'OAZON').show(4)
```

<div className='show-table'>
| OAZON | DKOD | DNEV  | FOGLALKOZAS | FONOKE | BELEPES   | FIZETES | JUTALEK | NEV        | TELEPHELY |
|-------|------|-------|-------------|--------|-----------|---------|---------|------------|-----------|
| 10    | 7839 | KING  | PRESIDENT   | 0      | 81-NOV-17 | 5000    | 0       | ACCOUNTING | NEW YORK  |
| 30    | 7698 | BLAKE | MANAGER     | 7839   | 81-MAY-01 | 2850    | 0       | SALES      | CHICAGO   |
| 10    | 7782 | CLARK | MANAGER     | 7839   | 81-JUN-09 | 2450    | 0       | ACCOUNTING | NEW YORK  |
| 20    | 7566 | JONES | MANAGER     | 7839   | 81-APR-02 | 2975    | 0       | RESEARCH   | DALLAS    |
</div>
