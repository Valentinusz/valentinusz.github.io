# Maximum likelihood módszer

Adott egy $n$ független, azonos eloszlású elemből $X_1,X_2,\dots,X_n$ álló minta. Egyetlen ismeretlen paraméterünk van,
amit $\lambda$-val jelölünk.

Az $x_1,x_2,\dots,x_n$ elemek likelihood függvényének nevezük, és $\mathrm{L}(\lambda; x)$-el
jelöljük az

$$
f_\lambda(x) = g_\lambda(x_1) \cdot g_\lambda(x_2) \cdot \ldots \cdot g_\lambda(x_n)
$$

függvényt.

Egy mintahalmazra vonatkozó ML becslés alatt azt a $\lambda$ értéket írjük, melyre a mintahalmaz likelihood függvénye
maximális.

Ezt a maximális értéket nyilvánvalóan a likelihood függvény deriválásával tudjuk meghatározni. A likelihood függvény
egy sok tagból álló szorzatfüggvény így deriválása nehéz.

:::tip
A becslés során **célszerű a függvény logaritmusát** az ún. **log-likelihood** függvényt venni. Így a **logaritmus
azonosságait kihasználva**, jelentősen le tudjuk egyszerűsíteni a számításokat.

$$
\begin{align*}
\log_a(xy)                     &= \log_a(x) + \log_a(y) \\
\log_a\left(\frac{x}{y}\right) &= \log_a(x) - \log_a(y) \\
\log_a(x^n)                    &= n \cdot \log_a(x)
\end{align*}
$$
:::

:::example[Példa (4.3)]
Annak valószínűsége, hogy pontosan ilyen kombinációját kapjuk az értékeknek $c^4 \cdot (3c)^{10} \cdot (1-4c)^6$. Ez a
likelihood függvényünk. Ez egyszerűbb számolás érdekében vegyük ennek a logaritmusát.

Ekkor a log-likelihood függvény:

$$
\begin{align*}
\ln(c^4 \cdot (3c)^{10} \cdot (1-4c)^6) &= \ln{c^4} + \ln{(3c)^{10}} + \ln{(1-4c)^6} \\
&= 4 \ln{c} + 10 \ln{(3c)}          + 6 \ln{(1-4c)} \\
&= 4 \ln{c} + 10 \ln{3} + 10 \ln{c} + 6 \ln{(1-4c)}
\end{align*}
$$

A lokális szélsőértékre vonatkozó elsődleges feltétel miatt:

$$
\begin{align*}
0 &= \frac{4}{c} + 0 + \frac{10}{c} + \left(\frac{6}{1-4c} \cdot -4 \right) \\
&= \frac{14}{c} - \frac{24}{1-4c}  \\
&= \frac{14-56c - 24c}{c(1-4c)} \\
&= \frac{14-80c}{c(1-4c)}
\end{align*}
$$

Ez pontosan akkor nulla, ha a számláló nulla, azaz:
$$
14-80c = 0
$$

Így:
$$
c = \frac{7}{40}
$$

(Még le kéne ellenőrizni, hogy $c$ valóban maximum hely-e de ez már az analízis feladata.)
:::


:::example[Példa (4.4/a)]
Legyen $X$ egy $n$ elemből álló minta. Adjunk ML becslést $\mathrm{Bin}(m,p)$ eloszlás $p$ paraméterére!

Ekkor a log-likelihood függvény:

$$
\ln \prod_{i=0}^{n}{{m \choose x_i} \cdot p^{x_i} \cdot (1-p)^{m-x_i}}
$$

Ami a logaritmus tulajdonságai alapján:

$$
\begin{align*}
\ln \mathrm{L}(m, p, x) 
&= \sum_{i=0}^{n}{\ln{m \choose x_i}} + \sum_{i=0}^{n}{\ln{p^{x_i}}}     + \sum_{i=0}^{n}{\ln{(1-p)^{m-x_i}}} \\
&= \sum_{i=0}^{n}{\ln{m \choose x_i}} + \sum_{i=0}^{n}{x_i \cdot \ln{p}} + \sum_{i=0}^{n}{(m-x_i) \cdot \ln{(1-p)}} \\
&= \sum_{i=0}^{n}{\ln{m \choose x_i}} + \ln{p} \cdot \sum_{i=0}^{n}{x_i} + \ln{(1-p)} \cdot \sum_{i=0}^{n}{(m-x_i)}
\end{align*}
$$


Mivel $x_i$ adott minden $i < n$ esetén, illetve ismerjük $m$-et, ezért csak $p$ szerint kell deriválni:

$$
\begin{align*}
(\ln \mathrm{L}(m, p, x))'
&= 0 + \frac{1}{p} \sum_{i=0}^{n}{x_i} + \frac{-1}{1-p} \sum_{i=0}^{n}{(m-x_i)} \\
&= \frac{1}{p} \sum_{i=0}^{n}{x_i} - \frac{1}{1-p} \cdot \left( nm - \sum_{i=0}^{n}{x_i} \right)
\end{align*}
$$

Vegyük észre hogy az előbb kapott egyenletben a mintaáltag $\overline{x}$ szerepel, ekkor $p$ becsléséhez a következő
egyenletet kell megoldanunk:

$$
\begin{align*}
\frac{1}{p} n \bar{x} &= \frac{1}{1-p} \cdot (nm - n\bar{x}) \\
(1-p) \cdot n \bar{x} &= p \cdot (nm - n\bar{x}) \\
n \cdot \bar{x} - p \cdot n\bar{x} &= p \cdot nm - p \cdot n\bar{x} \\
n \cdot \bar{x} &= p \cdot nm \\
\bar{x} &= pm \\
p &= \frac{\bar{x}}{m} \\

\end{align*}
$$

Tehát $p$-re a $\frac{\bar{x}}{m}$ becslést tudjuk adni.
:::
